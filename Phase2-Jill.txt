Jill's Updates for Phase 2 Deliverables:

Presentation: (Logan/Mihal)

Description of the data exploration phase of the project:
How we are:
- How we are Loading in Images to S3
- How we are processing the .mat files
- How we are loading metadata into R3 Database

SEE BELOW


Main Branch:

Outline of Project (Jill to Add to Readme)

- How we are Loading in Images to S3
- How we are processing the .mat files
- How we are loading metadata into R3 Database
 
ADDED TO README - Jill


Machine Learning Model:

- Description of preliminary data preprocessing
- See above?
- Description of how data was split into training and testing sets

Described in ReadMe
Also see Below


Database:

- Present a fully integrated Database - Done (see below and related images)
- new create_database.sql - Done 
- new ERD design - Done
- process to upload to db - Done
- proof database is populated - Done
	images/label-table.png
	images/image_count.png
- how model will use db before/during/after - Described below
- how model will use SqlAlchemy and Postgres - In Readme


Outline of Project:   Current Thought Process

1)  Choose Data Set:  Stanford Dataset
2)  Load Dataset 
	a) Create Python File to read Dataset metadata files - stanford_readdata.ipynb
		- create DataFrame - labels for definition of types of cars in dataset.
		images/df_labels.png
		- create DataFrame - df_train for definition of types of cars in training dataset.
		images/df_train.png
		images/df_train_w_labels.png
		- create DataFrame - df_test for definition of types of cars in testing dataset.
		images/df_test.png	
	b) Create  AWS Buckets -  cars-traindatset, cars-testdataset
		- Use AWS R3 Upload Tool to move images from PC to cars-traindataset
		- Use AWS R3 Upload Tool to move images from PC to cars-testdataset
	c) Create AWS PostgreSQL Database
		images/Database.png
		- Create tables - labels, images in cars database for dataset
		- Populate tables - from DataFrames, lables, df_train, df_test
		images/class_count_train.png
		images/Training-Dataset-Loaded.png
		images/Image-Table.png
3)  Run Train/Test Machine Model on Data Set
	a)  Read Database and create dataframe from :
		- Query merging images with labels for training dataset 
		- Train Model
		- Optimize model until your model accuracy is what you want.
	b) Test model by:
		- Query database with images for testing dataset 
		- Match with labels available
		- See if Model can correctly predict test images.
	c) Update Test Image Class
		- Create new dataframe / update df_train ? to include class column
		- Update database table image with test image new value for class.
4)  Application Development
	a) Save accurate model into Pickle file
	b) Create Flask application using Pickle file
	c) Deploy Application (allow someone to upload an image and app returns car/not car or what type of car)
	
	
	
	
	
 * The Training of the Model needs to:
    * read the database, 
    * find the location of the Training images on the file system, 
    * read the image, 
    * run it through the model,
    * train the model based on the label,
    * predict the accuracy,
    * Save the Model.
  * The Testing of the model needs to:
    * Read the database
    * find the location of the test images on the file systems
    * read the image(s),
    * Rerun the Saved Model on the test data, 
    * update the database of the training data,
    * with the label it determined the image was,
    * calculate the accuracy
	
	
